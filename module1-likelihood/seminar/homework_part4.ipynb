{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c527540d",
   "metadata": {},
   "source": [
    "# Homework 1. Likelihood-based models\n",
    "\n",
    "- Task 1 (5 points): Warmup\n",
    "- Task 2 (10 points): PixelCNN\n",
    "- Task 3 (10 points): Conditional PixelCNN\n",
    "- **Task 4 (10 points): RealNVP**\n",
    "- \\* Bonus (10+++ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e9c70",
   "metadata": {},
   "source": [
    "# Task 4. 2D Continuous Data. RealNVP flow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a04645",
   "metadata": {},
   "source": [
    "In this part we will build flow model, transforming given 2D continuous distribution to uniform 2D distribution. Our distribution will be represented as a set of samples. We will use RealNVP model, which we discussed on lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1217b4",
   "metadata": {},
   "source": [
    "First of all, we define function for data sampling, use it and perform train/val/test split as usual. This time all elements also have labels, associated with them. We wil use them for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    count = 100000\n",
    "    rand = np.random.RandomState(0)\n",
    "    a = [[-1.5, 2.5]] + rand.randn(count // 3, 2) * 0.2\n",
    "    b = [[1.5, 2.5]] + rand.randn(count // 3, 2) * 0.2\n",
    "    c = np.c_[2 * np.cos(np.linspace(0, np.pi, count // 3)),\n",
    "    -np.sin(np.linspace(0, np.pi, count // 3))]\n",
    "\n",
    "    c += rand.randn(*c.shape) * 0.2\n",
    "    data_x = np.concatenate([a, b, c], axis=0)\n",
    "    data_y = np.array([0] * len(a) + [1] * len(b) + [2] * len(c))\n",
    "    perm = rand.permutation(len(data_x))\n",
    "    return data_x[perm], data_y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = sample_data()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fa21b",
   "metadata": {},
   "source": [
    "Let's take a look on a 2D histogram of our train set distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfd405",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(X_train.T[0], X_train.T[1], bins=100, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafdc1ff",
   "metadata": {},
   "source": [
    "Let's also visualize distribution in point form with different colors, associated with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train.T[0], X_train.T[1], c = Y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321136e",
   "metadata": {},
   "source": [
    "We will build RealNVP flow model using affine coupling layer as main building block. In two-coordinates case it takes the following form:\n",
    "\n",
    "$$ (x_1, x_2) \\rightarrow (z_1, z_2) $$\n",
    "$$ z_1 = x_1 $$\n",
    "$$ z_2 = x_2 \\cdot \\sigma(s(x_1)) + t(x_1) $$\n",
    "\n",
    "Where vector from $s, t$ values is calculated as neural network with $x_1$ on input and $\\sigma$ is sigmoid function. Cool thing about RealNVP is that this network can be arbitrary complex and doesn't need to be invertible itself to have invertible flow for affine coupling layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42164782",
   "metadata": {},
   "source": [
    "Flows support composition and we will use it. In general, we will compose our total flow in the following way:\n",
    "\n",
    "$$ (z_1, z_2) = (\\sigma \\circ f_{\\theta, 1} \\circ \\dots \\circ f_{\\theta, n})(x_1, x_2) $$\n",
    "\n",
    "Where $f_{\\theta, i}$ is affine coupling layers described above. And $\\sigma$ is elementwise sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe46247",
   "metadata": {},
   "source": [
    "Important thing in flows training is loss function. In case of flows composition, log-likelihood objective takes the following form:\n",
    "\n",
    "$$ \\log p_\\theta(x) = \\log p_\\theta(z) + \\sum_i \\log | \\det \\frac{\\partial f_i}{\\partial f_{i-1}}| $$\n",
    "\n",
    "Here $\\det \\frac{\\partial f_i}{\\partial f_{i-1}}$ is Jacobian matrix determinant for each flow operation. And $\\log p_\\theta(z)$ is log likelihood of latent space we are mapping to (in our case $U(0, 1)^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f0e2c",
   "metadata": {},
   "source": [
    "Answer the following questions (you will need the answers to complete your RealNVP model code):\n",
    "\n",
    "1. What is $\\log | \\det \\frac{\\partial f_i}{\\partial f_{i-1}} |$ for affine coupling operation?\n",
    "2. What is $\\log | \\det \\frac{\\partial f_i}{\\partial f_{i-1}} |$ for elementwise sigmoid operation?\n",
    "3. What are the inverse operations for both sigmoid and affine coupling?\n",
    "4. How $\\log p_\\theta(z)$ in case of $U(0, 1)^2$ can be calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c97fe6",
   "metadata": {},
   "source": [
    "We will start implementation of RealNVP from affine coupling layer. You will need to implement inverse operation calculations as well as objective update for each layer ($\\log | \\det \\frac{\\partial f_i}{\\partial f_{i-1}} |$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, num_features=2):\n",
    "        super(AffineCoupling, self).__init__()\n",
    "        # Store your NN model for s and t values calculation\n",
    "        # Your network should take num_features // 2 elements on input (1 in our case)\n",
    "        # And return num_features elements on output (1 in our case)\n",
    "        self.NN = # YOUR CODE HERE\n",
    "    \n",
    "    # Forward pass is implemented for you. Implement your objective update\n",
    "    def forward(self, x, objective):\n",
    "        z1, z2 = torch.chunk(x, 2, dim=1)\n",
    "        h = self.NN(z1)\n",
    "        shift = h[:, 0::2]\n",
    "        \n",
    "        scale = torch.sigmoid(h[:, 1::2])\n",
    "        z2 += shift\n",
    "        z2 *= scale\n",
    "        objective += # YOUR CODE HERE\n",
    "        \n",
    "        return torch.cat([z1, z2], dim=1), objective\n",
    "    \n",
    "    # Implement reverse value calculation\n",
    "    def reverse(self, x):\n",
    "        ################\n",
    "        # YOUR CODE HERE\n",
    "        ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1cd55",
   "metadata": {},
   "source": [
    "Now do the same for elementwise sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementwise sigmoid flow from R^n to (0; 1)^n\n",
    "class ElementwiseSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ElementwiseSigmoid, self).__init__()\n",
    "    \n",
    "    def forward(self, x, objective):\n",
    "        x = torch.sigmoid(x)\n",
    "        objective += # YOUR CODE HERE\n",
    "        return x, objective\n",
    "    \n",
    "    def reverse(self, x):\n",
    "        ################\n",
    "        # YOUR CODE HERE\n",
    "        ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4f2de",
   "metadata": {},
   "source": [
    "We will also need to swap dimensions from time to time for affine couling layer, so it leaves different parts of input the same on different iterations. Answer the following questions:\n",
    "1. Is this operation legal? Is it a flow? What is the reverse operation?\n",
    "2. That is $\\log | \\det \\frac{\\partial f_i}{\\partial f_{i-1}} |$ for this operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4619f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensions_swap(x):\n",
    "    x1, x2 = torch.chunk(x, 2, dim=1)\n",
    "    return torch.cat([x2, x1], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acef8d",
   "metadata": {},
   "source": [
    "Finally, we build RealNVP model from defined operations. Feel free to change number of affine coupling layers inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, n_transforms=4):\n",
    "        super(RealNVP, self).__init__()\n",
    "        \n",
    "        self.affines = nn.ModuleList([AffineCoupling() for _ in range(n_transforms)])\n",
    "        self.sigmoid = ElementwiseSigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        objective = 0\n",
    "        for layer in self.affines:\n",
    "            x, objective = layer(x, objective)\n",
    "            x = dimensions_swap(x)\n",
    "\n",
    "        x, objective = self.sigmoid(x, objective)\n",
    "        \n",
    "        return x, objective\n",
    "    \n",
    "    def reverse(self, x):\n",
    "        x = self.sigmoid.reverse(x)\n",
    "        for layer in reversed(self.affines):\n",
    "            x = dimensions_swap(x)\n",
    "            x = layer.reverse(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de9aa4",
   "metadata": {},
   "source": [
    "At last, we define training procedure. Here we have calculated our total objective from flows log-det-s, however, we still need to define our loss, which we need to minimize. We also want to accumulate training loss values in bits. Fill this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_realnvp(model, train_data, batch_size = 512, lr = 0.001, num_epochs = 5):\n",
    "    dataset = torch.utils.data.TensorDataset(torch.Tensor(train_data).to(device))\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        for X_train in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions, objective = model(X_train[0])\n",
    "            \n",
    "            # Define your total loss value here\n",
    "            loss = # YOUR CODE HERE\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(\n",
    "                # Store the value of total NLL here\n",
    "                # YOUR CODE HERE\n",
    "            )\n",
    "            \n",
    "    print(\"Train NLL(bits)\")\n",
    "    plt.plot(train_losses, color='green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144649e",
   "metadata": {},
   "source": [
    "Create the model and launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "realnvp = RealNVP().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_realnvp(realnvp, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1b6fd",
   "metadata": {},
   "source": [
    "Now evaluate your model: calculate NLL in bits on your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "realnvp.eval()\n",
    "\n",
    "# Implement NLL calculation on X_val data\n",
    "################\n",
    "# YOUR CODE HERE\n",
    "###############\n",
    "val_nll_bits = # YOUR CODE HERE\n",
    "print(\"NLL on validation set in bits: {}\".format(val_nll_bits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5afd634",
   "metadata": {},
   "source": [
    "Feel free to tune your model parameters to improve your NLL score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e5f6e",
   "metadata": {},
   "source": [
    "Now it's time for some visualizations! Let's calculate flow values of our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_flow = realnvp(torch.Tensor(X_val).to(device))[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85e4fc",
   "metadata": {},
   "source": [
    "Now we will visualize our points before and after passing throw the flow, leaving the label color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_val.T[0], X_val.T[1], c = Y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4097415",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sampled_flow.T[0], sampled_flow.T[1], c = Y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439840e",
   "metadata": {},
   "source": [
    "Finally, let's perform sampling from RealNVP and visualize their histogram to compare with testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f134953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_realnvp(model):\n",
    "    x1 = random.random()\n",
    "    x2 = random.random()\n",
    "    latent = torch.Tensor([[x1, x2]]).to(device)\n",
    "    result = realnvp.reverse(latent)[0]\n",
    "    \n",
    "    return result.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fcdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = [sample_from_realnvp(realnvp) for _ in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870367c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = np.array(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(sampled_data.T[0], sampled_data.T[1], bins=100, cmap='gray',range=[[-3, 3], [-2, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(X_test.T[0], X_test.T[1], bins=100, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
